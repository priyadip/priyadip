# Priyadip Sau

**M.Tech in Artificial Intelligence** | Indian Institute of Technology Jodhpur  
*Research Focus: Parameter-Efficient Fine-Tuning, Large Language Models, Multi-Modal Representation Learning*

[![Website](https://img.shields.io/badge/Portfolio-priyadipsau.in-0A66C2?style=flat-square)](https://priyadipsau.in/)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-priyadip--cs-0A66C2?style=flat-square&logo=linkedin)](https://linkedin.com/in/priyadip-cs)
[![Google Scholar](https://img.shields.io/badge/Scholar-Profile-4285F4?style=flat-square&logo=googlescholar)](https://scholar.google.com/)
[![Twitter](https://img.shields.io/badge/X-@PriyadipSau-000000?style=flat-square&logo=x)](https://x.com/PriyadipSau)

---

## About

I am a graduate researcher at IIT Jodhpur specializing in efficient adaptation methods for large language models and multi-modal representation learning. My work sits at the intersection of **natural language understanding**, **parameter-efficient fine-tuning (PEFT)**, and **scalable ML systems**—with a particular emphasis on persona alignment, quantization-aware training, and contrastive learning frameworks.

Prior to my M.Tech, I completed my M.Sc. in Mathematics, which provides a rigorous foundation in optimization theory, linear algebra, and statistical inference that informs my approach to deep learning research.

**Current Interests:**
- Low-rank adaptation (LoRA/QLoRA) for LLM alignment and behavioral steering
- Multi-modal fusion architectures for large-scale clustering
- Efficient inference pipelines and serverless GPU deployment
- Evaluation frameworks for generative models (perplexity, similarity metrics)

---

## Selected Projects

### Sherlock-LLM: Persona Alignment via Parameter-Efficient Fine-Tuning
*Fine-tuning Qwen-2.5 for rigorous persona adoption using QLoRA (4-bit NF4 quantization)*

- Implemented low-rank adaptation (r=16) on Qwen-2.5-7B with BitsAndBytes quantization
- Designed dual-metric evaluation: Conditional Perplexity & Jaccard Similarity for persona steering
- Achieved perplexity reduction from 45.31 → 7.52; deployed via Modal serverless API

`Python` `PyTorch` `Hugging Face (PEFT, TRL)` `QLoRA` `BitsAndBytes` `Modal` `FastAPI`

---

### Advanced Multi-Modal Customer Segmentation
*End-to-end deep learning pipeline fusing demographic, textual (S-BERT), and behavioral (LSTM) modalities*

- Engineered multi-modal encoder with dual-loss training (Contrastive + Clustering)
- Processed 1.36M+ customer embeddings with GPU-accelerated HDBSCAN
- Achieved 0.901 Silhouette Score on large-scale segmentation benchmark

`Python` `PyTorch` `SentenceTransformers` `LSTM` `cuML (RAPIDS)` `HDBSCAN`

---

### Rice Dataset Classification
*ResNet-18 trained from scratch for fine-grained visual classification*

- Achieved 99.87% accuracy on 5-class rice species classification after 20 epochs
- Executed on Kaggle GPU runtime with efficient data augmentation pipeline

`Python` `PyTorch` `Pillow`

---

## Tech Stack

**Languages**

![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![C](https://img.shields.io/badge/C-A8B9CC?style=for-the-badge&logo=c&logoColor=black)
![C++](https://img.shields.io/badge/C++-00599C?style=for-the-badge&logo=cplusplus&logoColor=white)
![SQL](https://img.shields.io/badge/SQL-4479A1?style=for-the-badge&logo=postgresql&logoColor=white)

**Deep Learning & ML Frameworks**

![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)
![Hugging Face](https://img.shields.io/badge/HuggingFace-FFD21E?style=for-the-badge&logo=huggingface&logoColor=black)
![scikit-learn](https://img.shields.io/badge/scikit--learn-F7931E?style=for-the-badge&logo=scikitlearn&logoColor=white)
![NumPy](https://img.shields.io/badge/NumPy-013243?style=for-the-badge&logo=numpy&logoColor=white)
![Pandas](https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white)
![Matplotlib](https://img.shields.io/badge/Matplotlib-11557C?style=for-the-badge)

**LLM & GenAI**

![QLoRA](https://img.shields.io/badge/QLoRA-FF6F00?style=for-the-badge)
![LoRA](https://img.shields.io/badge/LoRA-FF9800?style=for-the-badge)
![PEFT](https://img.shields.io/badge/PEFT-7C4DFF?style=for-the-badge)
![Transformers](https://img.shields.io/badge/Transformers-FFD21E?style=for-the-badge&logo=huggingface&logoColor=black)
![BitsAndBytes](https://img.shields.io/badge/BitsAndBytes-00C853?style=for-the-badge)
![CUDA](https://img.shields.io/badge/CUDA-76B900?style=for-the-badge&logo=nvidia&logoColor=white)

**Infrastructure & Tools**

![Modal](https://img.shields.io/badge/Modal-000000?style=for-the-badge)
![FastAPI](https://img.shields.io/badge/FastAPI-009688?style=for-the-badge&logo=fastapi&logoColor=white)
![Git](https://img.shields.io/badge/Git-F05032?style=for-the-badge&logo=git&logoColor=white)
![Linux](https://img.shields.io/badge/Linux-FCC624?style=for-the-badge&logo=linux&logoColor=black)
![Jupyter](https://img.shields.io/badge/Jupyter-F37626?style=for-the-badge&logo=jupyter&logoColor=white)
![VS Code](https://img.shields.io/badge/VS_Code-007ACC?style=for-the-badge&logo=visualstudiocode&logoColor=white)
![Google Colab](https://img.shields.io/badge/Colab-F9AB00?style=for-the-badge&logo=googlecolab&logoColor=white)
![Kaggle](https://img.shields.io/badge/Kaggle-20BEFF?style=for-the-badge&logo=kaggle&logoColor=white)
![LaTeX](https://img.shields.io/badge/LaTeX-008080?style=for-the-badge&logo=latex&logoColor=white)

---

## Education

| Degree | Institution | Performance | Year |
|--------|-------------|-------------|------|
| M.Tech (Artificial Intelligence) | IIT Jodhpur | 9.5 CGPA (Sem-1) | 2025–2027 |
| M.Sc. (Mathematics) | University of North Bengal | 6.46 CGPA | 2021–2023 |
| B.Sc. (Mathematics) | Vidyasagar University | 8.62 CGPA | 2018–2021 |

**GATE Data Science & AI 2025:** AIR 226 (Score: 717)

---

## Experience

**Teaching Assistant** — *IIT Jodhpur*  
Introduction to Machine Learning (July 2025 – December 2025)

---

## GitHub Analytics


<p align="center">
  <img
    src="https://streak-stats.demolab.com?user=priyadip&theme=github-dark-blue&hide_border=true"
    height="170"
  />
</p>

<p align="center">
  <img src="https://github-readme-activity-graph.vercel.app/graph?username=priyadip&theme=github-dark&hide_border=true&area=true" alt="Contribution Graph"/>
</p>

<p align="center">
  <img src="https://komarev.com/ghpvc/?username=priyadip&color=blueviolet&style=flat-square&label=Profile+Views" alt="Profile Views"/>
</p>


---

## Contact

For research collaborations, discussions on LLM alignment, or PEFT methodologies:

- **Email:** [m25csa023@iitj.ac.in](mailto:m25csa023@iitj.ac.in) | [saupriyadip571@gmail.com](mailto:saupriyadip571@gmail.com)
- **Portfolio:** [priyadipsau.in](https://priyadipsau.in/)

---

<p align="center">
  <i>"The goal is not to build models that perform well, but models that generalize wisely."</i>
</p>
